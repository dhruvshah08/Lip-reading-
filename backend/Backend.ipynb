{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zVPS_i9Mk3Q",
        "outputId": "32092c2c-2b12-4bc6-a391-cd0e0116a4b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (6.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n",
            "/content\n",
            "fatal: destination path 'av_hubert' already exists and is not an empty directory.\n",
            "/content/av_hubert\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.10/dist-packages (0.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-video in /usr/local/lib/python3.10/dist-packages (1.1.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from scikit-video) (8.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-video) (1.10.1)\n",
            "/content/av_hubert/fairseq\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/av_hubert/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (0.29.34)\n",
            "Requirement already satisfied: hydra-core<1.1 in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (1.0.7)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2.0.6)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2022.10.31)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2.3.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq==1.0.0a0+afc77bd) (1.22.4)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.10/dist-packages (from hydra-core<1.1->fairseq==1.0.0a0+afc77bd) (4.8)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+afc77bd) (4.5.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (2.7.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (0.8.10)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+afc77bd) (4.9.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==1.0.0a0+afc77bd) (2.21)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq==1.0.0a0+afc77bd) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq==1.0.0a0+afc77bd) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq==1.0.0a0+afc77bd) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->fairseq==1.0.0a0+afc77bd) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq==1.0.0a0+afc77bd) (1.3.0)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-1.0.0a0+afc77bd-cp310-cp310-linux_x86_64.whl size=2351393 sha256=a4e88720f84b5bf37caa6784be20c720071ccbb8fad4cdbc7c9c57f77651c173\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-08ws022l/wheels/9d/d5/16/2858bd41b3c8f8a9994060d9742bf0c2277ddbd72d53c55737\n",
            "Successfully built fairseq\n",
            "Installing collected packages: fairseq\n",
            "  Attempting uninstall: fairseq\n",
            "    Found existing installation: fairseq 1.0.0a0+afc77bd\n",
            "    Uninstalling fairseq-1.0.0a0+afc77bd:\n",
            "      Successfully uninstalled fairseq-1.0.0a0+afc77bd\n",
            "Successfully installed fairseq-1.0.0a0+afc77bd\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fer in /usr/local/lib/python3.10/dist-packages (22.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fer) (3.7.1)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from fer) (4.7.0.72)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fer) (2.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fer) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fer) (2.27.1)\n",
            "Requirement already satisfied: facenet-pytorch in /usr/local/lib/python3.10/dist-packages (from fer) (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fer) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch->fer) (1.22.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch->fer) (0.15.2+cu118)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from facenet-pytorch->fer) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fer) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fer) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fer) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fer) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fer) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fer) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fer) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fer) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fer) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fer) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->fer) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fer) (3.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->fer) (1.16.0)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision->facenet-pytorch->fer) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch->fer) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch->fer) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch->fer) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch->fer) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch->fer) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision->facenet-pytorch->fer) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->facenet-pytorch->fer) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision->facenet-pytorch->fer) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision->facenet-pytorch->fer) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision->facenet-pytorch->fer) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio==2.4.1 in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (1.22.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imageio==2.4.1) (8.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "%cd /content/\n",
        "!git clone https://github.com/facebookresearch/av_hubert.git\n",
        "\n",
        "%cd av_hubert\n",
        "!git submodule init\n",
        "!git submodule update\n",
        "!pip install scipy\n",
        "!pip install sentencepiece\n",
        "!pip install python_speech_features\n",
        "!pip install scikit-video\n",
        "\n",
        "%cd fairseq\n",
        "!pip install ./\n",
        "!pip install fer\n",
        "!pip install imageio==2.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyR3F9vKM_z7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81434911-f338-4747-efd1-5846ea0ea53c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-02 08:12:31--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
            "Resolving dlib.net (dlib.net)... 107.180.26.78\n",
            "Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64040097 (61M)\n",
            "Saving to: ‘/content/data/misc/shape_predictor_68_face_landmarks.dat.bz2’\n",
            "\n",
            "/content/data/misc/ 100%[===================>]  61.07M  15.7MB/s    in 6.0s    \n",
            "\n",
            "2023-06-02 08:12:37 (10.3 MB/s) - ‘/content/data/misc/shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n",
            "\n",
            "bzip2: Output file /content/data/misc/shape_predictor_68_face_landmarks.dat already exists.\n",
            "--2023-06-02 08:12:37--  https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/raw/master/preprocessing/20words_mean_face.npy\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/master/preprocessing/20words_mean_face.npy [following]\n",
            "--2023-06-02 08:12:38--  https://raw.githubusercontent.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/master/preprocessing/20words_mean_face.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1168 (1.1K) [application/octet-stream]\n",
            "Saving to: ‘/content/data/misc/20words_mean_face.npy’\n",
            "\n",
            "/content/data/misc/ 100%[===================>]   1.14K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-02 08:12:38 (45.0 MB/s) - ‘/content/data/misc/20words_mean_face.npy’ saved [1168/1168]\n",
            "\n",
            "--2023-06-02 08:12:38--  https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/vsr/base_vox_433h.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.156.60.69, 108.156.60.51, 108.156.60.36, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.156.60.69|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1928063847 (1.8G) [binary/octet-stream]\n",
            "Saving to: ‘/content/data/finetune-model.pt’\n",
            "\n",
            "/content/data/finet 100%[===================>]   1.79G   192MB/s    in 7.9s    \n",
            "\n",
            "2023-06-02 08:12:46 (232 MB/s) - ‘/content/data/finetune-model.pt’ saved [1928063847/1928063847]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p /content/data/misc/\n",
        "!mkdir -p /content/data/framedata\n",
        "!wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2 -O /content/data/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!bzip2 -d /content/data/misc/shape_predictor_68_face_landmarks.dat.bz2\n",
        "!wget --content-disposition https://github.com/mpc001/Lipreading_using_Temporal_Convolutional_Networks/raw/master/preprocessing/20words_mean_face.npy -O /content/data/misc/20words_mean_face.npy\n",
        "!wget https://dl.fbaipublicfiles.com/avhubert/model/lrs3_vox/vsr/base_vox_433h.pt -O /content/data/finetune-model.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GtStQ96NDxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfe90e29-9248-4463-e19c-cab1ba6f87c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxTx2iZtNHb9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "!killall ngrok\n",
        "pid = os.getpid()\n",
        "!kill -9 $pid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzDVF5kgNKEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02f5ba2-060c-4e4b-80cb-bfad9e99018d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/av_hubert/avhubert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'FLASK_ENV' is deprecated and will not be used in Flask 2.3. Use 'FLASK_DEBUG' instead.\n",
            "WARNING:pyngrok.process.ngrok:t=2023-06-02T09:19:09+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"https://affe-34-147-52-157.ngrok-free.app\" -> \"http://127.0.0.1:5000\"\n",
            " * Serving Flask app '__main__'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'FLASK_ENV' is deprecated and will not be used in Flask 2.3. Use 'FLASK_DEBUG' instead.\n",
            "'FLASK_ENV' is deprecated and will not be used in Flask 2.3. Use 'FLASK_DEBUG' instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd /content/av_hubert/avhubert/\n",
        "import dlib, cv2, os\n",
        "import numpy as np\n",
        "import skvideo\n",
        "import skvideo.io\n",
        "from tqdm import tqdm\n",
        "from preparation.align_mouth import landmarks_interpolate, crop_patch, write_video_ffmpeg\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "import tempfile\n",
        "from argparse import Namespace\n",
        "import fairseq\n",
        "from fairseq import checkpoint_utils, options, tasks, utils\n",
        "from fairseq.dataclass.configs import GenerationConfig\n",
        "from IPython.display import HTML\n",
        "\n",
        "import threading\n",
        "from flask import Flask, request, jsonify\n",
        "from werkzeug.utils import secure_filename\n",
        "from pyngrok import ngrok\n",
        "\n",
        "from fer import FER\n",
        "\n",
        "\n",
        "def play_video(video_path, width=200):\n",
        "  mp4 = open(video_path,'rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  return HTML(f\"\"\"\n",
        "  <video width={width} controls>\n",
        "        <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\")\n",
        "\n",
        "def detect_landmark(image, detector, predictor):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    rects = detector(gray, 1)\n",
        "    coords = None\n",
        "    for (_, rect) in enumerate(rects):\n",
        "        shape = predictor(gray, rect)\n",
        "        coords = np.zeros((68, 2), dtype=np.int32)\n",
        "        for i in range(0, 68):\n",
        "            coords[i] = (shape.part(i).x, shape.part(i).y)\n",
        "    return coords\n",
        "\n",
        "def preprocess_video(input_video_path, output_video_path, face_predictor_path, mean_face_path):\n",
        "  print(1)\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  print(1)\n",
        "  predictor = dlib.shape_predictor(face_predictor_path)\n",
        "  print(1)\n",
        "  STD_SIZE = (256, 256)\n",
        "  print(1)\n",
        "  mean_face_landmarks = np.load(mean_face_path)\n",
        "  print(1)\n",
        "  stablePntsIDs = [33, 36, 39, 42, 45]\n",
        "  print(1)\n",
        "  videogen = skvideo.io.vread(input_video_path)\n",
        "  print(1)\n",
        "  frames = np.array([frame for frame in videogen])\n",
        "  print(1)\n",
        "  landmarks = []\n",
        "  for frame in tqdm(frames):\n",
        "      landmark = detect_landmark(frame, detector, predictor)\n",
        "      landmarks.append(landmark)\n",
        "  preprocessed_landmarks = landmarks_interpolate(landmarks)\n",
        "  rois = crop_patch(input_video_path, preprocessed_landmarks, mean_face_landmarks, stablePntsIDs, STD_SIZE, \n",
        "                        window_margin=12, start_idx=48, stop_idx=68, crop_height=96, crop_width=96)\n",
        "  write_video_ffmpeg(rois, output_video_path, \"/usr/bin/ffmpeg\")\n",
        "  return\n",
        "\n",
        "def getEmotion():\n",
        "  folder_name = '/content/data/framedata'\n",
        "  map_of_emotions = dict();\n",
        "  map_of_emotions[0] = 'angry';\n",
        "  map_of_emotions[1] = 'cheerful';\n",
        "  map_of_emotions[2] = 'fearful'; \n",
        "  map_of_emotions[3] = 'sad';\n",
        "  map_of_emotions[4] = 'chat';\n",
        "  map_of_emotions[5] = 'disgruntled';\n",
        "  map_of_emotions[6] = 'excited';\n",
        "  list_of_emotions=[];\n",
        "  for i in range(0,7):\n",
        "      list_of_emotions.append(0)\n",
        "  item = '/content/data/clip.mp4'\n",
        "  vid = cv2.VideoCapture(item)\n",
        "  currentframe = 0\n",
        "  emo_detector = FER(mtcnn=True)\n",
        "  while (True):\n",
        "      success, frame = vid.read()\n",
        "      if success:\n",
        "          name1 = folder_name+'/frame' + str(currentframe) + '.jpg'\n",
        "          cv2.imwrite(name1, frame)\n",
        "          currentframe += 1\n",
        "          test_image_one = cv2.imread(name1)\n",
        "          dominant_emotion,score = emo_detector.top_emotion(test_image_one)\n",
        "          if dominant_emotion == \"angry\":\n",
        "              list_of_emotions[0]+=1; \n",
        "          elif dominant_emotion == \"happy\":\n",
        "              list_of_emotions[1]+=1;\n",
        "          elif dominant_emotion == \"fear\":\n",
        "              list_of_emotions[2]+=1;\n",
        "          elif dominant_emotion == \"sad\":\n",
        "              list_of_emotions[3]+=1;\n",
        "          elif dominant_emotion == \"neutral\":\n",
        "              list_of_emotions[4]+=1;\n",
        "          elif dominant_emotion == \"disgust\":\n",
        "              list_of_emotions[5]+=1;\n",
        "          elif dominant_emotion == \"surprise\":\n",
        "              list_of_emotions[6]+=1;\n",
        "      else:\n",
        "          break\n",
        "  vid.release()\n",
        "  cv2.destroyAllWindows()\n",
        "  max_emotion_count = list_of_emotions[0]\n",
        "  max_emotion = map_of_emotions[0]\n",
        "  for i in range(1,7):\n",
        "      count = list_of_emotions[i]\n",
        "      if count>max_emotion_count:\n",
        "          max_emotion_count = count\n",
        "          max_emotion = map_of_emotions[i]\n",
        "  #print('MAXIMUM EMOTION  - ', max_emotion)\n",
        "  return max_emotion\n",
        "\n",
        "def predict(video_path, ckpt_path, user_dir):\n",
        "  print(0)\n",
        "  num_frames = int(cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  print(1)\n",
        "  data_dir = tempfile.mkdtemp()\n",
        "  print(2)\n",
        "  tsv_cont = [\"/\\n\", f\"test-0\\t{video_path}\\t{None}\\t{num_frames}\\t{int(16_000*num_frames/25)}\\n\"]\n",
        "  print(3)\n",
        "  label_cont = [\"DUMMY\\n\"]\n",
        "  print(4)\n",
        "  with open(f\"{data_dir}/test.tsv\", \"w\") as fo:\n",
        "    fo.write(\"\".join(tsv_cont))\n",
        "  with open(f\"{data_dir}/test.wrd\", \"w\") as fo:\n",
        "    fo.write(\"\".join(label_cont))\n",
        "  print(5)\n",
        "  utils.import_user_module(Namespace(user_dir=user_dir))\n",
        "  print(6)\n",
        "  modalities = [\"video\"]\n",
        "  gen_subset = \"test\"\n",
        "  gen_cfg = GenerationConfig(beam=20)\n",
        "  print(7)\n",
        "  models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task([ckpt_path])\n",
        "  print(8)\n",
        "  models = [model.eval().cuda() for model in models]\n",
        "  print(9)\n",
        "  saved_cfg.task.modalities = modalities\n",
        "  saved_cfg.task.data = data_dir\n",
        "  saved_cfg.task.label_dir = data_dir\n",
        "  print(10)\n",
        "  task = tasks.setup_task(saved_cfg.task)\n",
        "  task.load_dataset(gen_subset, task_cfg=saved_cfg.task)\n",
        "  print(11)\n",
        "  generator = task.build_generator(models, gen_cfg)\n",
        "  print(12)\n",
        "\n",
        "  def decode_fn(x):\n",
        "      dictionary = task.target_dictionary\n",
        "      symbols_ignore = generator.symbols_to_strip_from_output\n",
        "      symbols_ignore.add(dictionary.pad())\n",
        "      return task.datasets[gen_subset].label_processors[0].decode(x, symbols_ignore)\n",
        "  \n",
        "  itr = task.get_batch_iterator(dataset=task.dataset(gen_subset)).next_epoch_itr(shuffle=False)\n",
        "  sample = next(itr)\n",
        "  sample = utils.move_to_cuda(sample)\n",
        "  hypos = task.inference_step(generator, models, sample)\n",
        "  ref = decode_fn(sample['target'][0].int().cpu())\n",
        "  hypo = hypos[0][0]['tokens'].int().cpu()\n",
        "  hypo = decode_fn(hypo)\n",
        "  return hypo\n",
        "\n",
        "\n",
        "\n",
        "face_predictor_path = \"/content/data/misc/shape_predictor_68_face_landmarks.dat\"\n",
        "mean_face_path = \"/content/data/misc/20words_mean_face.npy\"\n",
        "origin_clip_path = \"/content/data/clip.mp4\"\n",
        "mouth_roi_path = \"/content/data/roi.mp4\"\n",
        "\n",
        "\n",
        "ckpt_path = \"/content/data/finetune-model.pt\"\n",
        "ckpt_path_hindi = \"/content/gdrive/MyDrive/final/exp1/checkpoints/checkpoint_last.pt\"\n",
        "user_dir = \"/content/av_hubert/avhubert\"\n",
        "\n",
        "os.environ[\"FLASK_ENV\"] = \"development\"\n",
        "app = Flask(__name__)\n",
        "port = 5000\n",
        "\n",
        "ngrok.set_auth_token(\"2LApBWQWx5ep57uYtAZ1egBcQl5_82cYLVbfPHabeWrTbGRcr\")\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url,port))\n",
        "\n",
        "app.config[\"BASE_URL\"] = public_url\n",
        "app.config[\"UPLOAD_FOLDER\"] = '/content/data/'\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "  return \"Hi\"\n",
        "\n",
        "@app.route(\"/aakash\")\n",
        "def aakash():\n",
        "  return \"Aakash\"\n",
        "\n",
        "\n",
        "@app.route(\"/upload\", methods=['POST'])\n",
        "def upload_video():\n",
        "  if 'file' not in request.files:\n",
        "    return jsonify({'error' : 'Media not provided'}), 400\n",
        "  file = request.files['file']\n",
        "  if file.filename == '':\n",
        "    return jsonify({'error': 'No file selected'}), 400\n",
        "  if file:\n",
        "    filename = secure_filename(file.filename)\n",
        "    file.save(os.path.join(app.config['UPLOAD_FOLDER'], \"clip.mp4\"))\n",
        "    preprocess_video(origin_clip_path, mouth_roi_path, face_predictor_path, mean_face_path)\n",
        "    hypo = predict(mouth_roi_path, ckpt_path, user_dir)\n",
        "    emotion = getEmotion()\n",
        "  return jsonify({'msg' : hypo,'emotion' : emotion})\n",
        "\n",
        "\n",
        "@app.route(\"/upload_hindi\", methods=['POST'])\n",
        "def upload_video_hindi():\n",
        "  if 'file' not in request.files:\n",
        "    return jsonify({'error' : 'Media not provided'}), 901\n",
        "  file = request.files['file']\n",
        "  if file.filename == '':\n",
        "    return jsonify({'error': 'No file selected'}), 900\n",
        "  if file:\n",
        "    filename = secure_filename(file.filename)\n",
        "    file.save(os.path.join(app.config['UPLOAD_FOLDER'], \"clip.mp4\"))\n",
        "    preprocess_video(origin_clip_path, mouth_roi_path, face_predictor_path, mean_face_path)\n",
        "    hypo = predict(mouth_roi_path, ckpt_path_hindi, user_dir)\n",
        "    print(hypo)\n",
        "    emotion = getEmotion()\n",
        "    print(emotion)\n",
        "  return jsonify({'msg' : hypo,'emotion' : emotion})\n",
        "\n",
        "threading.Thread(target=app.run,kwargs={\"use_reloader\": False}).start()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}