# Lip-reading

We propose a lipreading system that lip-reads sentences from a video or in real-time using a camera that would cover a wide range of
vocabulary. Various applications already exist that help lipread but do not solve the problem of the multi-language barrier.
We also detect the emotion of the person speaking in the video input. This is used to produce an audio output where
the audio is played in that specific emotion. The text output given by our application can be converted into any language
according to the needs of the user. Moreover, most proposals lip-read word-by word and we did this process by a sentenceby-sentence basis. We hope to cater to people with disabilities, a focus not employed before. We created our own dataset to test this framework. Our dataset focuses on 2 languages- Hindi
and English. Furthermore, we cater to mixed-language speech recognition as well.

The project is made using android studio, java and python and is made by fine-tuning with Meta's Avhubert model.
